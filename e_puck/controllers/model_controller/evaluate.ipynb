{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confronto tra progressive_val_score e implementazione personalizzata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from river import datasets\n",
    "from river import stream\n",
    "from river import metrics\n",
    "from river import linear_model\n",
    "from river.evaluate import progressive_val_score\n",
    "from river import preprocessing\n",
    "import logging\n",
    "from river import forest,drift,tree\n",
    "from Oespl import OESPL\n",
    "\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparazione dei dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "b = pd.read_csv(r\"C:\\Users\\franc\\Desktop\\TESI\\SML_thesis_line_follower_robot\\e_puck\\data\\data\\sensors_data\\train_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = b.drop(columns=['target'])\n",
    "y = b['target']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementazione personalizzata di progressive_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_progressive_val_score(dataset, model, metric, print_every=None):\n",
    "    for i, (x, y) in enumerate(dataset):\n",
    "        x = dict(x) if isinstance(x, pd.Series) else x  # Ensure x is a dict\n",
    "        y_pred = model.predict_one(x)\n",
    "        if y_pred is not None:\n",
    "            old_metric = metric # Convert to float to avoid references\n",
    "            metric.update(y_true=y, y_pred=y_pred)\n",
    "            #logger.debug(f\"Step {i}: y_true={y}, y_pred={y_pred:.4f}, metric before={old_metric.get():.4f}, metric after={metric.get():.4f}\")\n",
    "        model.learn_one(x, y)\n",
    "\n",
    "        if print_every and i % print_every == 0:\n",
    "            print(f\"[{i}] {metric}\")\n",
    "\n",
    "    return metric.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confronto tra i due metodi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,000] MAE: 17.670057\n",
      "[2,000] MAE: 17.645193\n",
      "[3,000] MAE: 17.201596\n",
      "[4,000] MAE: 16.912333\n",
      "[5,000] MAE: 17.062971\n",
      "[6,000] MAE: 16.956905\n",
      "[7,000] MAE: 17.095356\n",
      "[8,000] MAE: 16.610703\n",
      "[9,000] MAE: 16.632725\n",
      "[10,000] MAE: 16.269243\n",
      "[11,000] MAE: 16.267041\n",
      "[11,036] MAE: 16.229564\n",
      "Progressive validation score: MAE: 16.229564\n",
      "[0] MAE: 199.998847\n",
      "[1000] MAE: 17.654681\n",
      "[2000] MAE: 17.64179\n",
      "[3000] MAE: 17.198109\n",
      "[4000] MAE: 16.908222\n",
      "[5000] MAE: 17.065489\n",
      "[6000] MAE: 16.956195\n",
      "[7000] MAE: 17.093223\n",
      "[8000] MAE: 16.613387\n",
      "[9000] MAE: 16.632654\n",
      "[10000] MAE: 16.269339\n",
      "[11000] MAE: 16.265683\n",
      "Custom progressive validation score: 16.22956419628686\n",
      "Differenza tra i risultati: 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = (preprocessing.StandardScaler() | OESPL(\n",
    "            base_estimator=tree.HoeffdingTreeRegressor(),\n",
    "            ensemble_size=3,\n",
    "            lambda_fixed=6.0,\n",
    "            seed=42,\n",
    "            drift_detector=drift.ADWIN(),\n",
    "            patience=1000,\n",
    "            awakening=500,\n",
    "            reset_model=True\n",
    "        ))\n",
    "metric = metrics.MAE()\n",
    "# Valutazione con progressive_val_score standard\n",
    "streams1 = stream.iter_pandas(X, y, shuffle=True, seed=42)\n",
    "result1 = progressive_val_score(dataset=streams1, model=model, metric=metric, print_every=1000)\n",
    "print(f'Progressive validation score: {result1}')\n",
    "\n",
    "metric = metrics.MAE()\n",
    "model = (preprocessing.StandardScaler() | OESPL(\n",
    "            base_estimator=tree.HoeffdingTreeRegressor(),\n",
    "            ensemble_size=3,\n",
    "            lambda_fixed=6.0,\n",
    "            seed=42,\n",
    "            drift_detector=drift.ADWIN(),\n",
    "            patience=1000,\n",
    "            awakening=500,\n",
    "            reset_model=True\n",
    "        ))\n",
    "# Valutazione con implementazione personalizzata\n",
    "streams2 = stream.iter_pandas(X, y, shuffle=True, seed=42)\n",
    "result2 = custom_progressive_val_score(dataset=streams2, model=model, metric=metric, print_every=1000)\n",
    "print(f'Custom progressive validation score: {result2}')\n",
    "\n",
    "# Confronto dei risultati\n",
    "print(f'Differenza tra i risultati: {abs(result1.get() - result2)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisi delle differenze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
